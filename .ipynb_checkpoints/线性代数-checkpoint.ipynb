{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以将向量视为标量值组成的列表。我们将这些标量值称为向量的元素（element）或分量（component)。我们通过一维张量处理向量。一般来说，张量可以具有任意长度，取决于机器的内存限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在代码中，我们通过张量的索引来访问任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。与普通的Python数组一样，我们可以通过调用Python的内置len()函数来访问张量的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当用张量表示一个向量（只有一个轴）时，我们也可以通过.shape属性访问向量的长度。 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于只有一个轴的张量，形状只有一个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当调用函数来实例化张量时， 我们可以通过指定两个分量m和n来创建一个形状为m x n的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(20).reshape(5, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为方阵的一种特殊类型，对称矩阵（symmetric matrix）A 等于其转置：A = A.T 这里我们定义一个对称矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "b == b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任何按元素的一元运算都不会改变其操作数的形状。 同样，给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量。 例如，将两个相同形状的矩阵相加，会在这两个矩阵上执行元素加法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "====================================================================================================\n",
      "tensor([[ 0.,  2.,  4.,  6.],\n",
      "        [ 8., 10., 12., 14.],\n",
      "        [16., 18., 20., 22.],\n",
      "        [24., 26., 28., 30.],\n",
      "        [32., 34., 36., 38.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "b = a.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "print(a)\n",
    "print('='*100)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9],\n",
      "         [10, 11, 12, 13]],\n",
      "\n",
      "        [[14, 15, 16, 17],\n",
      "         [18, 19, 20, 21],\n",
      "         [22, 23, 24, 25]]])\n",
      "====================================================================================================\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "x = torch.arange(24).reshape(2, 3, 4)\n",
    "print(a + x)\n",
    "print('='*100)\n",
    "print((a * x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以对任意张量进行的一个有用的操作是计算其元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "====================================================================================================\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "print(x)\n",
    "print('='*100)\n",
    "print(x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。 我们还可以指定张量沿哪一个轴来通过求和降低维度。 以矩阵为例，为了通过求和所有行的元素来降维（轴0），我们可以在调用函数时指定axis=0。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "torch.Size([2, 3, 4])\n",
      "====================================================================================================\n",
      "tensor([[12., 14., 16., 18.],\n",
      "        [20., 22., 24., 26.],\n",
      "        [28., 30., 32., 34.]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(24,dtype=torch.float32).reshape(2,3,4)\n",
    "a_sum_axis0 = a.sum(axis=0)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print('='*100)\n",
    "print(a_sum_axis0)\n",
    "print(a_sum_axis0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定axis=1将通过汇总所有列的元素降维（轴1）。因此，输入轴1的维数在输出形状中消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12., 15., 18., 21.],\n",
      "        [48., 51., 54., 57.]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a_sum_axis1 = a.sum(axis=1)\n",
    "print(a_sum_axis1)\n",
    "print(a_sum_axis1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(276.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个与求和相关的量是平均值（mean或average）。 我们通过将总和除以元素总数来计算平均值。 在代码中，我们可以调用函数来计算任意形状张量的平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.5000)\n",
      "====================================================================================================\n",
      "tensor(11.5000)\n"
     ]
    }
   ],
   "source": [
    "print(a.mean())\n",
    "print('='*100)\n",
    "print(a.sum() / a.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，计算平均值的函数也可以沿指定轴降低张量的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.]])\n",
      "====================================================================================================\n",
      "tensor([[ 6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.]])\n"
     ]
    }
   ],
   "source": [
    "print(a.mean(axis=0))\n",
    "print('='*100)\n",
    "print(a.sum(axis=0) / a.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[12., 15., 18., 21.]],\n",
       "\n",
       "        [[48., 51., 54., 57.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_a = a.sum(axis=1, keepdim=True)\n",
    "sum_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过广播将A除以sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0667, 0.1111, 0.1429],\n",
       "         [0.3333, 0.3333, 0.3333, 0.3333],\n",
       "         [0.6667, 0.6000, 0.5556, 0.5238]],\n",
       "\n",
       "        [[0.2500, 0.2549, 0.2593, 0.2632],\n",
       "         [0.3333, 0.3333, 0.3333, 0.3333],\n",
       "         [0.4167, 0.4118, 0.4074, 0.4035]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / sum_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想沿某个轴计算A元素的累积总和， 比如axis=0（按行计算），我们可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n",
      "====================================================================================================\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [12, 15, 18, 21],\n",
      "        [24, 28, 32, 36],\n",
      "        [40, 45, 50, 55]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(20).reshape(5, 4)\n",
    "print(a)\n",
    "print('='*100)\n",
    "print(a.cumsum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**点积** 所有相同位置的元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([0., 1., 2., 3.])\n",
      "====================================================================================================\n",
      "y:  tensor([1., 1., 1., 1.])\n",
      "====================================================================================================\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "print('x: ',x)\n",
    "print('='*100)\n",
    "print('y: ',y)\n",
    "print('='*100)\n",
    "print(torch.dot(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码中使用张量表示矩阵-向量积，我们使用与点积相同的mv函数。 当我们为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积。 注意，A的列维数（沿轴1的长度）必须与x的维数（其长度）相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "torch.Size([4])\n",
      "tensor([ 14.,  38.,  62.,  86., 110.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(20,dtype=torch.float32).reshape(5, 4)\n",
    "b = torch.arange(4,dtype=torch.float32)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(torch.mv(a,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵-矩阵乘法**AB**看作是简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n x m矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6338, 0.2039, 0.6381],\n",
      "        [0.9581, 0.3071, 0.6643],\n",
      "        [0.4179, 0.4129, 0.4743],\n",
      "        [0.7269, 0.6557, 0.1165]])\n",
      "====================================================================================================\n",
      "tensor([[0.7762, 0.7181, 0.1199, 0.0068],\n",
      "        [0.6461, 0.3539, 0.4729, 0.5796],\n",
      "        [0.9522, 0.4110, 0.4399, 0.2737]])\n",
      "====================================================================================================\n",
      "tensor([[1.2314, 0.7896, 0.4532, 0.2971],\n",
      "        [1.5747, 1.0697, 0.5523, 0.3663],\n",
      "        [1.0428, 0.6412, 0.4540, 0.3720],\n",
      "        [1.0988, 0.8019, 0.4485, 0.4168]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3)\n",
    "b = torch.rand(3, 4)\n",
    "print(a)\n",
    "print('='*100)\n",
    "print(b)\n",
    "print('='*100)\n",
    "print(torch.mm(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性代数中最有用的一些运算符是范数（norm）。 非正式地说，一个向量的范数告诉我们一个向量有多大。 这里考虑的大小（size）概念不涉及维度，而是分量的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, 4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frobenius范数满足向量范数的所有性质，它就像是矩阵形向量的**L**范数。 调用以下函数将计算矩阵的Frobenius范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4,9)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
